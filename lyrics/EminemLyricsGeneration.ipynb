{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EminemGeneration.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uKQ2eJfgHkVF","colab_type":"code","colab":{}},"source":["'''\n","#Keras Example script to generate text from Nietzsche's writings.\n","\n","At least 20 epochs are required before the generated text\n","starts sounding coherent.\n","\n","It is recommended to run this script on GPU, as recurrent\n","networks are quite computationally intensive.\n","\n","If you try this script on new data, make sure your corpus\n","has at least ~100k characters. ~1M is better.\n","'''\n","\n","from __future__ import print_function\n","from keras.callbacks import LambdaCallback\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.optimizers import RMSprop\n","from keras.utils.data_utils import get_file\n","import pandas as pd \n","import numpy as np\n","import random\n","import sys\n","import io"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9vKjIo9gXkE","colab_type":"code","colab":{}},"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7r43pXuYCMy","colab_type":"code","colab":{}},"source":["def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQnIyyB-YGs1","colab_type":"code","colab":{}},"source":["def on_epoch_end(epoch, _):\n","    # Function invoked at end of each epoch. Prints generated text.\n","    # print()\n","    # print('----- Generating text after Epoch: %d' % epoch)\n","\n","    # start_index = random.randint(0, len(text) - maxlen - 1)\n","    # for diversity in [0.2, 0.5, 1.0, 1.2]:\n","    #     print('----- diversity:', diversity)\n","\n","    #     generated = ''\n","    #     sentence = text[start_index: start_index + maxlen]\n","    #     generated += sentence\n","    #     print('----- Generating with seed: \"' + sentence + '\"')\n","    #     sys.stdout.write(generated)\n","\n","    #     for i in range(400):\n","    #         x_pred = np.zeros((1, maxlen, len(chars)))\n","    #         for t, char in enumerate(sentence):\n","    #             x_pred[0, t, char_indices[char]] = 1.\n","\n","    #         preds = model.predict(x_pred, verbose=0)[0]\n","    #         next_index = sample(preds, diversity)\n","    #         next_char = indices_char[next_index]\n","\n","    #         sentence = sentence[1:] + next_char\n","\n","    #         sys.stdout.write(next_char)\n","    #         sys.stdout.flush()\n","    #     print()\n","    None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wd2Eum1K4EDU","colab_type":"code","colab":{}},"source":["def generate_output():\n","    generated = ''\n","    usr_input = input(\"Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: \")\n","    # zero pad the sentence to Tx characters.\n","    sentence = ('{0:0>' + str(Tx) + '}').format(usr_input).lower()\n","    generated += usr_input \n","\n","    sys.stdout.write(\"\\n\\nHere is your poem: \\n\\n\") \n","    sys.stdout.write(usr_input)\n","    for i in range(400):\n","\n","        x_pred = np.zeros((1, Tx, len(chars)))\n","\n","        for t, char in enumerate(sentence):\n","            if char != '0':\n","                x_pred[0, t, char_indices[char]] = 1.\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = sample(preds, temperature = 1.0)\n","        next_char = indices_char[next_index]\n","\n","        generated += next_char\n","        sentence = sentence[1:] + next_char\n","\n","        sys.stdout.write(next_char)\n","        sys.stdout.flush()\n","\n","        if next_char == '\\n':\n","            continue"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFttcbQ-IDQ3","colab_type":"code","colab":{}},"source":["# path = get_file(\n","#     'nietzsche.txt',\n","#     origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","# with io.open(path, encoding='utf-8') as f:\n","#     text = f.read().lower()\n","# print('corpus length:', len(text))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uAVMkAYp5beD","colab_type":"code","colab":{}},"source":["# text[:100]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"USyEgi2h5S_r","colab_type":"code","outputId":"f915d24f-ecc2-4c95-8089-a26676c6d6fa","executionInfo":{"status":"ok","timestamp":1574793982945,"user_tz":300,"elapsed":24444,"user":{"displayName":"Constance Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGjf1yRw1ZrrL5ypYtJwNgSRGNxWVAJasRfSjA=s64","userId":"04555242777359091791"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Freestyle/songdata.csv\")\n","eminem = list(data[(data['artist'] == 'Eminem')]['text'])\n","text = ''\n","for i in range(len(eminem)):\n","  text += eminem[i].lower()\n","print('corpus length:', len(text))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","corpus length: 194271\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"axmhehNAJ_fK","colab_type":"code","outputId":"baba0a4f-1376-4837-8434-18b95b0b36f4","executionInfo":{"status":"ok","timestamp":1574793988047,"user_tz":300,"elapsed":860,"user":{"displayName":"Constance Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGjf1yRw1ZrrL5ypYtJwNgSRGNxWVAJasRfSjA=s64","userId":"04555242777359091791"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total chars: 50\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tfU59IUVNgoq","colab_type":"code","outputId":"408cc0af-3c78-4d5c-a1ea-58702b1c0a0b","executionInfo":{"status":"ok","timestamp":1574793990752,"user_tz":300,"elapsed":920,"user":{"displayName":"Constance Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGjf1yRw1ZrrL5ypYtJwNgSRGNxWVAJasRfSjA=s64","userId":"04555242777359091791"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# cut the text in semi-redundant sequences of maxlen characters\n","maxlen = 40\n","step = 3\n","sentences = []\n","next_chars = []\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('nb sequences:', len(sentences))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["nb sequences: 64744\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oWmeKgvXysP","colab_type":"code","outputId":"698c6c14-8c2f-4210-bbff-14fb8765bd60","executionInfo":{"status":"ok","timestamp":1574793998176,"user_tz":300,"elapsed":1374,"user":{"displayName":"Constance Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGjf1yRw1ZrrL5ypYtJwNgSRGNxWVAJasRfSjA=s64","userId":"04555242777359091791"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('Vectorization...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Vectorization...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PqV5Cz7CX5zm","colab_type":"code","colab":{}},"source":["# build the model: a single LSTM\n","# print('Build model...')\n","# maxlen = 40\n","# model = Sequential()\n","# model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n","# model.add(Dense(len(chars), activation='softmax'))\n","\n","# optimizer = RMSprop(lr=0.01)\n","# model.compile(loss='categorical_crossentropy', optimizer=optimizer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"upDyYlmKfJMk","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","epochs_total = 150\n","model = load_model('/content/drive/My Drive/Colab Notebooks/Freestyle/keras_model_'+ str(epochs_total) + '.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-bi74crYJ4f","colab_type":"code","outputId":"a9c30287-868c-43ae-9ac4-2ac4cf5da9c7","executionInfo":{"status":"ok","timestamp":1574739523146,"user_tz":300,"elapsed":99537,"user":{"displayName":"Constance Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGjf1yRw1ZrrL5ypYtJwNgSRGNxWVAJasRfSjA=s64","userId":"04555242777359091791"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","model.fit(x, y,\n","          batch_size=128,\n","          epochs=75,\n","          callbacks=[print_callback])\n","epochs_total = 225\n","model.save('/content/drive/My Drive/Colab Notebooks/Freestyle/keras_model_'+ str(epochs_total) + '.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/75\n","64744/64744 [==============================] - 45s 694us/step - loss: 0.7881\n","Epoch 2/75\n","64744/64744 [==============================] - 43s 669us/step - loss: 0.7915\n","Epoch 3/75\n","64744/64744 [==============================] - 44s 672us/step - loss: 0.7899\n","Epoch 4/75\n","64744/64744 [==============================] - 43s 667us/step - loss: 0.7871\n","Epoch 5/75\n","64744/64744 [==============================] - 44s 673us/step - loss: 0.7835\n","Epoch 6/75\n","64744/64744 [==============================] - 43s 672us/step - loss: 0.7802\n","Epoch 7/75\n","64744/64744 [==============================] - 44s 682us/step - loss: 0.7774\n","Epoch 8/75\n","64744/64744 [==============================] - 44s 673us/step - loss: 0.7796\n","Epoch 9/75\n","64744/64744 [==============================] - 44s 674us/step - loss: 0.7774\n","Epoch 10/75\n","64744/64744 [==============================] - 43s 671us/step - loss: 0.7802\n","Epoch 11/75\n","64744/64744 [==============================] - 43s 667us/step - loss: 0.7794\n","Epoch 12/75\n","64744/64744 [==============================] - 44s 674us/step - loss: 0.7768\n","Epoch 13/75\n","64744/64744 [==============================] - 43s 668us/step - loss: 0.7790\n","Epoch 14/75\n","64744/64744 [==============================] - 43s 670us/step - loss: 0.7780\n","Epoch 15/75\n","64744/64744 [==============================] - 43s 665us/step - loss: 0.7732\n","Epoch 16/75\n","64744/64744 [==============================] - 43s 664us/step - loss: 0.7761\n","Epoch 17/75\n","64744/64744 [==============================] - 43s 662us/step - loss: 0.7702\n","Epoch 18/75\n","64744/64744 [==============================] - 43s 662us/step - loss: 0.7744\n","Epoch 19/75\n","64744/64744 [==============================] - 43s 661us/step - loss: 0.7700\n","Epoch 20/75\n","64744/64744 [==============================] - 43s 665us/step - loss: 0.7674\n","Epoch 21/75\n","64744/64744 [==============================] - 43s 668us/step - loss: 0.7739\n","Epoch 22/75\n","64744/64744 [==============================] - 43s 660us/step - loss: 0.7691\n","Epoch 23/75\n","64744/64744 [==============================] - 43s 660us/step - loss: 0.7718\n","Epoch 24/75\n","64744/64744 [==============================] - 43s 660us/step - loss: 0.7641\n","Epoch 25/75\n","64744/64744 [==============================] - 43s 663us/step - loss: 0.7626\n","Epoch 26/75\n","64744/64744 [==============================] - 43s 663us/step - loss: 0.7680\n","Epoch 27/75\n","63360/64744 [============================>.] - ETA: 0s - loss: 0.7672"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pC_8w2U229nY","colab_type":"code","outputId":"0f345edc-a2c3-4360-86b5-6cbc2882c232","executionInfo":{"status":"ok","timestamp":1574727499306,"user_tz":300,"elapsed":16785,"user":{"displayName":"Constance Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGjf1yRw1ZrrL5ypYtJwNgSRGNxWVAJasRfSjA=s64","userId":"04555242777359091791"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["Tx = 40\n","generate_output()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: hello\n","\n","\n","Here is your poem: \n","\n","hellojecsa, but little bith-briffes  \n","gettin' that the seun chooze my said  \n","tried, it take up in oh wokes gooda man  \n","i'm like  \n","  \n","i never the surrus on my trounda niggas of else flock nokes the mind of haid  \n","maybe murd  \n","its get up in last  \n","ter you be doneekes what you gonna like  \n","with it  \n","i'm altex  \n","  \n","it well the first you we goes at like to a familif, spitting  \n","i'm instroit, ho'do, i'm dout"],"name":"stdout"}]}]}